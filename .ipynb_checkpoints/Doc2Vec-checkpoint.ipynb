{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import all the dependencies\n",
    "import gensim\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docLabels = []\n",
    "docLabels = [f for f in listdir('/home/sudharsan/Prac') if \n",
    " f.endswith('.txt')]\n",
    "#create a list data that stores the content of all text files in order of their names in docLabels\n",
    "data = []\n",
    "for doc in docLabels:\n",
    "      data.append(open( doc).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['accurate',\n",
       "  'total_words',\n",
       "  'argument',\n",
       "  'epochs',\n",
       "  'progres',\n",
       "  'rate',\n",
       "  'mistakes',\n",
       "  'corpus_count',\n",
       "  'examples',\n",
       "  'learning',\n",
       "  'sentences',\n",
       "  'around',\n",
       "  'provided',\n",
       "  'build_vocab',\n",
       "  'decay',\n",
       "  'avoid',\n",
       "  'initial',\n",
       "  'supplied',\n",
       "  'recommended',\n",
       "  'percentage',\n",
       "  'either',\n",
       "  'available',\n",
       "  'case',\n",
       "  'multiple',\n",
       "  'ability',\n",
       "  'alpha',\n",
       "  'train',\n",
       "  'total_examples',\n",
       "  'value',\n",
       "  'words',\n",
       "  'model\\xe2',\n",
       "  'corpus',\n",
       "  'must',\n",
       "  'count',\n",
       "  'training',\n",
       "  'passes',\n",
       "  'logging',\n",
       "  'raw',\n",
       "  'cached',\n",
       "  'linear',\n",
       "  'explicit',\n",
       "  'iter',\n",
       "  'called',\n",
       "  'common',\n",
       "  'property',\n",
       "  'min_alpha',\n",
       "  'support'],\n",
       " ['lda',\n",
       "  'filtering',\n",
       "  'challenging',\n",
       "  'text',\n",
       "  'topics',\n",
       "  'hard',\n",
       "  'it\\xe2',\n",
       "  'purposes',\n",
       "  'numeric',\n",
       "  'outcomes',\n",
       "  'topic',\n",
       "  'texts',\n",
       "  'tasks',\n",
       "  'learning',\n",
       "  'consideration',\n",
       "  'keywords',\n",
       "  'mediocre',\n",
       "  'loses',\n",
       "  'retrieval',\n",
       "  'techniques',\n",
       "  'web',\n",
       "  'use',\n",
       "  'documents',\n",
       "  'latent',\n",
       "  'since',\n",
       "  'spam',\n",
       "  'ordering',\n",
       "  'technique',\n",
       "  'machine',\n",
       "  'also',\n",
       "  'example',\n",
       "  'document',\n",
       "  'method',\n",
       "  'possible',\n",
       "  'etc',\n",
       "  'subtleties',\n",
       "  'good',\n",
       "  'mostly',\n",
       "  'may',\n",
       "  'evaluate',\n",
       "  'however',\n",
       "  'results',\n",
       "  'allocation',\n",
       "  'simplistic',\n",
       "  'task',\n",
       "  'words',\n",
       "  'known',\n",
       "  'modeling',\n",
       "  'tune',\n",
       "  'search',\n",
       "  'dirichlet',\n",
       "  'word',\n",
       "  'g',\n",
       "  'many',\n",
       "  'well',\n",
       "  'bow',\n",
       "  'bag',\n",
       "  'used',\n",
       "  'common',\n",
       "  'representation',\n",
       "  'e',\n",
       "  'extracting'],\n",
       " ['kingdom', 'king', 'everyone', 'slaves'],\n",
       " ['world', 'prince', 'rule'],\n",
       " ['java',\n",
       "  'language',\n",
       "  'many',\n",
       "  'completed',\n",
       "  'native',\n",
       "  'engineer',\n",
       "  'projects',\n",
       "  'software'],\n",
       " ['python', 'deep', 'machine', 'analytics', 'r', 'learning', 'data'],\n",
       " ['python',\n",
       "  'science',\n",
       "  'programming',\n",
       "  'artificial',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'intelligence',\n",
       "  'data']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc2.txt',\n",
       " 'new.txt',\n",
       " 'king.txt',\n",
       " 'doc1.txt',\n",
       " 'java.txt',\n",
       " 'dataanalytics.txt',\n",
       " 'datascience.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "#This function does all cleaning of data using two objects above\n",
    "def nlp_clean(data):\n",
    "   new_data = []\n",
    "   for d in data:\n",
    "      new_str = d.lower()\n",
    "      dlist = tokenizer.tokenize(new_str)\n",
    "      dlist = list(set(dlist).difference(stopword_set))\n",
    "      new_data.append(dlist)\n",
    "   return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "              yield gensim.models.doc2vec.LabeledSentence(doc,    \n",
    "[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = nlp_clean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iterator returned over all documents\n",
    "it = LabeledLineSentence(data, docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=300, min_count=0, alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    " model.train(it,total_examples=120, epochs=50)\n",
    " model.alpha -= 0.002\n",
    " model.min_alpha = model.alpha\n",
    " \n",
    " model.train(it,total_examples=120, epochs=50)\n",
    "#saving the created model\n",
    "model.save('doc2vec.model')\n",
    "print 'model saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.23287249  0.51272297 -1.26678693  1.39728451  2.30679798  1.04520977\n",
      " -2.41737533 -0.80992448 -0.11371329 -1.70952427  0.93931365  0.36956877\n",
      "  1.98067951 -0.02057174  1.21390557  2.23245716  0.35568264 -0.19237047\n",
      " -1.68702924 -1.22316909  3.59187031  1.97058189  0.40316659  0.05596895\n",
      "  0.9444285  -0.10080323 -0.99113917  0.72821218  0.90158939  0.21501681\n",
      " -1.09655833  1.62575376 -0.40215814  2.08935142 -1.39751983 -0.46089\n",
      "  2.08617091 -0.35882959  0.90858668 -0.8665722  -0.34596342 -0.45271271\n",
      " -2.53598094  0.38942838  1.36410475 -0.81572407 -4.06906128 -0.2322391\n",
      " -1.62924552 -0.30173928 -1.95153403  1.88761675 -0.28720778 -1.82052577\n",
      "  1.30026889  1.69524634  0.60077316  1.4678905   1.44568205  0.64407927\n",
      " -0.15343305  0.40816492 -2.34841728 -2.59014344 -0.95534682  2.74920392\n",
      " -0.56450981 -3.13123655 -1.91955221  1.28532541  1.53472733  1.52456534\n",
      "  0.65290964 -0.81665748  0.57883739  1.55753815 -2.10847139  1.49711943\n",
      " -2.00781894  0.94659686  0.09924906  0.89257127 -2.46330571  2.40727186\n",
      "  0.99082088  2.92601275 -0.05344159  1.17488229 -0.40317023 -2.23646498\n",
      "  2.54122758  1.16339993  2.72924232 -0.87696403 -2.38693476  1.83798659\n",
      "  1.88932073  0.47190782 -0.13125739  1.49058104 -2.44354439  0.64570224\n",
      "  0.90855747  2.23499727 -0.25606513  1.62549973 -1.22951758 -0.04235479\n",
      " -1.2943548   1.62744546  2.11641598  1.51422727 -1.47481251 -1.62177491\n",
      " -2.2150507  -3.6921587   0.01032373 -1.31955612  0.03250059  0.4809491\n",
      " -0.2519874  -0.15747848  1.20766389  3.1954658  -1.33180797 -0.112198\n",
      "  1.20858288 -1.56974959  0.17888495 -3.33693266  2.43311286  0.25660536\n",
      "  1.56370568 -0.32523212  1.54241204  0.25780278 -2.38906193 -3.86073685\n",
      "  0.99253041  1.94128656 -1.33155966  1.38145304 -1.40217996  0.77213579\n",
      "  2.23693705  3.52524543  1.38357818 -1.37251127 -2.50626779 -2.15202332\n",
      " -1.49859798  0.61668074 -2.48083377 -1.4376452  -2.70208335  1.34580863\n",
      " -0.57833546 -1.02267885 -0.43353572 -0.47185224  1.23277152  0.94599533\n",
      " -0.66711676  3.59199238 -1.29227495  1.41377771  2.2357924   0.41940609\n",
      " -2.50533962  0.34492722 -0.64055413  1.38758874  0.37011012  0.01546804\n",
      "  1.97679853 -1.58215034  0.91247231 -0.44287783 -2.13712525  0.17052445\n",
      "  2.10341835  1.62267959  0.17778705  0.85452658  0.41714501  1.52984142\n",
      " -0.26178673  1.25797558  0.58939326  0.65154254 -1.27339423 -0.35103631\n",
      "  1.60142589  1.02664173  0.73091996 -0.46913686 -3.16124201 -2.7966466\n",
      "  1.50334716  3.22030449 -2.77980328 -0.01234749 -0.4430441   1.16935551\n",
      "  2.24575663 -2.76389694 -1.69583893  2.06272292  0.34824458 -0.94346589\n",
      "  2.79009008  2.93538618  1.52994168 -1.52039731 -3.46465778  0.60431588\n",
      "  0.70152223  1.17901933 -1.33783042 -2.94091868  1.69731367  2.64062238\n",
      "  0.2007668  -2.35085964  2.49278331 -1.44099414  0.96586585  1.23492479\n",
      " -0.20956402 -0.89622432  1.57557809 -0.52824259 -4.31007004  0.05651016\n",
      "  0.63407707  0.50257003 -0.32583424 -1.86984873  1.42503452 -1.61832821\n",
      " -0.36478302 -2.59877253 -2.37552762 -1.58383453  1.71803212 -0.0969012\n",
      "  0.10513852  2.68441296  1.0874157   0.54165292  2.26404095 -0.33365679\n",
      "  0.90497905  0.19491617 -0.53674251 -1.17584884  0.33035669  2.24994326\n",
      "  2.73982334  1.81017101  1.97882819 -1.03067732  0.88779444 -2.01246905\n",
      "  1.50378394  1.75640023  0.31032184  2.616081    0.9625873  -0.99743497\n",
      " -4.47316122 -1.24531162  0.76372969  1.53664207 -3.39249849  1.36322844\n",
      "  1.18700564  0.82254899  2.42331195 -3.11780572 -0.21337436 -0.79488105\n",
      " -0.77613986  0.96039331  0.35338143  1.48057008  0.07458717 -1.64863837\n",
      " -0.23562722  2.0135746   2.7221694   2.196316   -1.04205024 -1.92012203\n",
      "  3.8310504   0.9302479   0.67189783 -0.53212392  0.99430299  1.17920852]\n"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec.load('doc2vec.model')\n",
    "#start testing\n",
    "#printing the vector of document at index 1 in docLabels\n",
    "docvec = d2v_model.docvecs[1]\n",
    "print docvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#printing the vector of the file using its name\n",
    "docvec = d2v_model.docvecs['doc1.txt'] #if string tag used in training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('doc1.txt', 0.8720936179161072), ('king.txt', 0.8599457740783691), ('dataanalytics.txt', 0.855202317237854), ('datascience.txt', 0.8526448011398315), ('new.txt', 0.7486141920089722), ('doc2.txt', -0.2100406289100647)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#to get most similar document with similarity scores using document-index\n",
    "similar_doc = d2v_model.docvecs.most_similar(4) \n",
    "print similar_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('datascience.txt', 0.9724803566932678), ('king.txt', 0.8571012020111084), ('doc1.txt', 0.855724036693573), ('java.txt', 0.855202317237854), ('new.txt', 0.7437994480133057), ('doc2.txt', -0.21625849604606628)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#to get most similar document with similarity scores using document- name\n",
    "sims = d2v_model.docvecs.most_similar('dataanalytics.txt')\n",
    "print sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#to get vector of document that are not present in corpus \n",
    "new_vector = d2v_model.infer_vector('java.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sims = d2v_model.docvecs.most_similar([new_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doc2.txt', 0.03915632143616676),\n",
       " ('doc1.txt', -0.04043085128068924),\n",
       " ('datascience.txt', -0.0410609170794487),\n",
       " ('dataanalytics.txt', -0.054691608995199203),\n",
       " ('new.txt', -0.05826951563358307),\n",
       " ('king.txt', -0.06460370123386383),\n",
       " ('java.txt', -0.06607958674430847)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
