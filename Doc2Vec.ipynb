{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple document classification using Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "import gensim\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docLabels = []\n",
    "docLabels = [f for f in listdir('/home/sudharsan/Prac/doc2vec') if \n",
    " f.endswith('.txt')]\n",
    "#create a list data that stores the content of all text files in order of their names in docLabels\n",
    "data = []\n",
    "for doc in docLabels:\n",
    "      data.append(open( doc).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc2.txt', 'doc1.txt', 'dataanalytics.txt', 'datascience.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "#This function does all cleaning of data using two objects above\n",
    "def nlp_clean(data):\n",
    "   new_data = []\n",
    "   for d in data:\n",
    "      new_str = d.lower()\n",
    "      dlist = tokenizer.tokenize(new_str)\n",
    "      dlist = list(set(dlist).difference(stopword_set))\n",
    "      new_data.append(dlist)\n",
    "   return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "              yield gensim.models.doc2vec.LabeledSentence(doc,    \n",
    "[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = nlp_clean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iterator returned over all documents\n",
    "it = LabeledLineSentence(data, docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=300, min_count=0, alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    " model.train(it,total_examples=120, epochs=50)\n",
    " model.alpha -= 0.002\n",
    " model.min_alpha = model.alpha\n",
    " \n",
    " model.train(it,total_examples=120, epochs=50)\n",
    "#saving the created model\n",
    "model.save('doc2vec.model')\n",
    "print 'model saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51677901  0.31258044 -0.65208143  0.38211957 -0.3599042  -0.18258128\n",
      " -0.14837013  0.12151566 -1.05993772 -0.44988567  0.31823382  0.01076245\n",
      "  1.34790671 -0.2969535  -0.34067938 -0.92943388  0.1199168  -1.06547785\n",
      "  0.10513712  1.07346499  0.50644928  0.12733546  1.03785872 -0.3308382\n",
      " -0.12249345  0.6081841  -0.3029393  -0.11394179 -0.50903821  0.34106588\n",
      "  0.77057219  0.43314776 -0.94055104 -0.08001107 -0.22514546 -1.27893746\n",
      "  1.31172657  0.6123817  -0.45724756 -0.01732037  0.18734178 -0.88062489\n",
      " -1.07519853 -0.56802016 -0.09084667  0.2063639  -1.24354613 -1.31610143\n",
      "  0.10989806 -0.30430138 -0.7379021   0.42618427 -0.39330876  0.07784735\n",
      " -0.47767255  0.27728522 -1.05520236 -0.10190082  0.05903171 -0.12078369\n",
      "  0.63227069  0.34822017 -0.32487381  0.79358453  0.97610193 -0.19995734\n",
      " -0.85193741 -1.80406082  0.38684225  0.69084144  1.08070779  0.03698773\n",
      " -0.41941971  0.80394578  1.22347963 -0.01613422  0.82045329 -0.46655262\n",
      " -0.84752238  1.19900119  0.50947136  0.96124256 -0.92122614 -0.47486326\n",
      " -0.62153232  0.41513652  0.45198363 -0.43088859 -0.1184338  -0.24880475\n",
      "  0.99154818  0.18606256  0.09403412 -0.04283842 -1.20108032 -0.23475672\n",
      "  1.53339159 -0.89815372  0.45940861  0.32872453  0.11247776 -0.70224583\n",
      "  0.25985357  0.91184735  0.32737631  0.61285806 -0.67830336 -0.86394769\n",
      " -0.54968572  0.74625045  1.84336317 -0.00921281  0.77390176 -0.40505496\n",
      " -1.24825788  0.21776573  0.13633221 -0.44420263 -0.3785271  -0.13109037\n",
      " -1.30711925  0.20752917 -0.14252785  0.91243142 -0.32822078  0.91476315\n",
      " -1.13739824 -0.83406842  1.06802249  0.17092676  0.70135474  0.53124088\n",
      "  0.25365132  0.03664993  0.69946742  0.83584052  0.3466875  -0.0349462\n",
      " -0.47542074 -1.14776826  0.83661544 -0.81064898  0.51280504  0.24046163\n",
      " -0.22590569  0.53399003 -0.52883816 -0.60378438 -0.38276359 -1.63914573\n",
      "  0.92900413 -0.50708044  0.31774032 -0.76376778 -1.25554788  0.64360851\n",
      "  0.1054051  -0.86447436  0.26570889  0.26627842 -0.27869487 -0.30323339\n",
      "  1.29536462 -0.00536031  0.17057624  0.4859882  -0.08723825 -0.21954469\n",
      " -0.52090091  1.43399823 -0.95332861  0.22533651 -0.7957828  -0.07696696\n",
      " -1.26023555  1.06662476 -0.33353472 -1.31740594  0.05718707 -0.56361586\n",
      "  0.65409297 -0.35955995 -1.01802111 -0.11617366  0.65163171 -0.40058064\n",
      " -0.05784288 -0.46451518 -0.10219973 -0.88087857  0.71041685  0.92721236\n",
      " -0.21494612  1.20286596  0.45614576 -1.33589339 -0.95402807 -0.45281515\n",
      "  1.71178329  0.60377276  0.14214703 -0.0333075   0.00503545  1.26161051\n",
      " -0.2450652   0.27569872  1.10964167  1.20137763 -0.55831891  0.27595043\n",
      " -0.24370655  0.09924255  0.61330724 -0.27774304 -0.06150004 -0.27401841\n",
      "  0.33216697 -1.19427645  0.93142986 -0.86253119  0.61580509  0.24650943\n",
      "  0.31401005 -0.39777148  0.55666351 -0.56392527  0.57353723 -0.49412763\n",
      "  0.46367696 -0.23026031  0.08451182 -1.30886197  0.07887655  1.09673798\n",
      " -1.28442156 -0.04662634  0.49061328 -0.42219514 -0.38622323 -0.16383174\n",
      "  0.83255911 -0.5445981  -0.49860698  0.49365819 -0.00446831  0.69552982\n",
      "  0.33170882  0.44836193  0.60418153 -0.42955694  0.22645162 -1.59281111\n",
      " -0.01918568 -0.948443   -0.55223185  0.12051353  0.18404363  1.79085422\n",
      " -1.21384847  0.37520918  0.08105385 -0.35731959  0.87359601 -0.74489355\n",
      " -0.67558539  1.10121751 -0.71170163  1.53992116 -1.08487701 -0.06562162\n",
      "  0.07736345 -0.51848882  0.72079676  0.64863503 -1.62437057 -0.75553715\n",
      "  0.01114684  1.00708437  0.97561705  0.03760537 -1.48550296 -0.4911617\n",
      " -1.70514262 -1.13220799  0.71969926 -0.20865756  0.96908194 -0.97721428\n",
      "  0.4766508  -0.30432171  0.21511306 -0.98964423  1.06934822 -1.52933908\n",
      "  0.09910288 -0.37087852  0.99729943 -0.31615371 -0.74984092  0.1595252 ]\n"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec.load('doc2vec.model')\n",
    "#start testing\n",
    "#printing the vector of document at index 1 in docLabels\n",
    "docvec = d2v_model.docvecs[1]\n",
    "print docvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#printing the vector of the file using its name\n",
    "docvec = d2v_model.docvecs['doc1.txt'] #if string tag used in training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('doc2.txt', 0.9900029897689819), ('dataanalytics.txt', 0.9897094368934631), ('doc1.txt', -0.1383509784936905)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#to get most similar document with similarity scores using document-index\n",
    "similar_doc = d2v_model.docvecs.most_similar(3) \n",
    "print similar_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('doc2.txt', 0.9974048733711243), ('datascience.txt', 0.9897094368934631), ('doc1.txt', -0.21821844577789307)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#to get most similar document with similarity scores using document- name\n",
    "sims = d2v_model.docvecs.most_similar('dataanalytics.txt')\n",
    "print sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#to get vector of document that are not present in corpus \n",
    "new_vector = d2v_model.infer_vector('java.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sims = d2v_model.docvecs.most_similar([new_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('datascience.txt', 0.01247432827949524),\n",
       " ('dataanalytics.txt', 0.007095709443092346),\n",
       " ('doc2.txt', 0.003996063955128193),\n",
       " ('doc1.txt', -0.019129103049635887)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
